Welcome back to Stanford 244W,
uh, Machine Learning with Graphs.
Um, in this part of the lecture,
I'm going to discuss applications of graph machine learning research and its impact,
uh, across many different, uh, applications.
So in mach- graph machine learning,
we can formulate different types of tasks.
We can formulate tasks at the level of individual nodes.
We can formulate tasks at the level of,
uh, edges, uh, which is pairs of nodes.
We can identify or define tasks at the level of subgraphs of nodes,
as well as the tasks at the level of the entire, um,
graphs like for a graph level prediction or, uh, graph generation.
And what I'm going to talk, uh,
next is go through these different levels of tasks and show you, uh,
different, uh, applications, uh,
and different domains where this type of methods models can be applied.
So for node level tasks,
we generally talk about node classification,
where we are trying to predict a property of a node.
For example, categorize, uh,
online users or categorize items.
In link prediction, we tried to predict whether there
are missing links between a pair of nodes.
One such example of this task is knowledge graph completion.
In, uh, graph level task like graph classification,
we try to categorize different graphs.
Uh, for example, we may want to represent molecules as,
uh, graphs and then predict properties of molecules.
This is especially interesting and important task
for drug design where we try to predict,
uh, properties of different,
uh, molecules, different drugs.
We can also perform clustering or community detection,
where the goal is to identify, um,
closely neat, uh, subparts of the graph, uh,
where nodes are densely connected or highly connected with each other.
Um, and application of these could be social circle detection.
And- and then there are also other types of tasks.
For example, graph generation or graph, um, uh, evolution,
where graph generation could be, for example,
used for drug discovery to generate novel molecular structures.
And graph- and predicting graph evolution is very useful, uh,
in physics where we wanna run accurate simulations of various kinds of physics phenomena,
and that can be represented, um, as a graph.
So in all these machine learning tasks, uh, we use, uh,
we use, uh, graphs, uh,
which leads to high, uh, impact applications.
And now I wanna give you some examples of them.
So first, I'm going to give you some examples of
node level machine learning applications.
So, um, a very recent one announced at the end of December,
uh, this year is,
uh, the following problem.
It's called protein folding,
where basically in our bodies,
we have these molecules called proteins that
regulate various biological processes, and for example,
the way that drugs, uh,
work is to bind or change behavior of
different proteins which then then changes the biological processes in our body,
and this way, uh, for example,
we- we- we get cured or we we heal.
Um, proteins are- are composed,
uh, um, of amino acids.
And we can think of our protein as a sequence of amino acids.
However, due magnetic and different kinds of forces,
these- these proteins are not these, um, uh,
chains or strains, but the- they are actually- they actually fold,
um, in very complex, uh, shapes.
And one of the very important problems in biology, a very, uh, um,
a problem that hasn't yet been solved is given up- a sequence of amino acids,
can you predict the 3D structure of the underlying protein?
So the computational task that, um,
scientists have been running competitions about since, um, uh,
'70s is about how do we computation- computationally predict
protein's 3D structure based solely on its amino acid sequence.
Um, and here I show you a few, um, uh,
the three-dimensional structure of two different proteins,
and what you can see is that- that this folding of
a protein is- is very complex based on its,
uh, amino acid structure.
So the question is,
given a sequence of amino acids,
can we predict the three-dimensional structure,
um, of the protein?
And this is the problem that has been just recently solved.
In the middle of December of, uh, 2020, uh,
DeepMind announced Alpa- AlphaFold that increased the performance, um,
or the accuracy of this,
uh, protein folding, uh,
applications by 30 percent all the way up to the values that are in high 90s.
And here I just show a couple of, um, uh,
titles of articles in media,
uh, about how an important, uh,
achievement this- this has been,
how it changed the biology forever,
how it solved the- one of the largest scientific open problems,
and how this will turbocharge drug discovery and all kinds of,
uh, important, um, implications that this has.
And what is interesting in this, uh, scientific, uh,
AI machine learning breakthrough is that the key idea that
made this possible was to represent the underlying,
uh, protein as a graph.
Uh, and here they represented it as a spatial graph,
where nodes in this graph were amino acids in the protein sequence,
and the edges corresponded to, um,
ami- to nodes- to amino acids that are spatially close to each other.
So this means that now given the positions, um,
of all the amino acids and the edges proximities between them,
the graph neural network, uh,
approach was trained that it predicted the new positions,
uh, of the- of the, um, amino acids.
And this way, uh, the folding of the protein was able to be simulated and the-
and the posi- the final positions of the molecules were able to be, uh, predicted.
So the key ingredient in making this work,
in making this scientific breakthrough in protein folding was
the use of graph representation and the graph neural network, uh, technology.
Now, uh, this was on the level of nodes,
where basically for every node in the graph,
we tried to predict its, um,
uh, position in space,
and this way, uh,
tell what is the three-dimensional organization of a protein.
Now we are going to talk about edge-level machine learning task,
where we are basically doing link prediction or trying to
understand relationship between different nodes.
The first example of this is in recommender systems,
where basically we can think of these as users interacting with items,
items being products, movies,
um, songs, and so on.
And nodes, uh, will be- we'll have two types of nodes.
We will have users, and we would have items.
And there is an edge between a user and an item if a user consumed, bought,
reviewed, uh, a given item or listened to a given song or,
uh, watched a given movie.
And based on the structure of this graph and the properties of the users and the items,
we would like to predict or recommend
what other items given users might be interested in, uh, in the future.
So we naturally have a bipartite graph and, um, a graph problem.
And the modern recommender systems used in companies like, uh,
Pinterest, LinkedIn, uh, Facebook,
uh, Instagram, uh, Alibaba,
um, and elsewhere are all based on these graphical representations
and use graph representation learning and graph neural networks to make predictions.
And the key insight here is that we can basically
learn how to embed or how to represent nodes,
um, of this graph such that related nodes are
embedded closer to each other than nodes that are not related.
And for example, in case of Pinterest,
we can think of, uh,
Pinterest images as nodes in the graph,
and the goal is to embed, um,
nodes that are related- images that are related
closer together than images that are not related.
For example, this, uh,
sweater and the cake.
And the way one can do this is to create this type of bipartite network,
where we have the images on the top, and we can have,
for example, users or Pinterest boards at the bottom.
And then we can define a neural network approach that will take
the feature information or attribute information of these different pins,
so basically the content of the image,
and transform it across the underlying graph to come up with a robust embedding,
uh, of a given, uh, image.
And it turns out that this approach works much,
much better than if you would just consider images by themselves.
So images plus the graph structure leads to
much better recommendations than the image themselves.
So here in this example of the task,
it is about understanding relationships between pairs of nodes or pairs of
images by basically saying that nodes that are
related should be embedded closer together,
the distance between them should be smaller than the distance between,
uh, pairs of images that are not related to each other.
Um, another example of a link level prediction task is very different.
This is about, uh,
drug combination side effects.
Uh, the problem here is that many patients take
multiple drugs simultaneously to trick- to treat complex and coexisting diseases.
For example, in the United States, basically,
fif- 50 percent of people over 70 years of age simultaneously take four or,
uh, five or more drugs.
And there are many patients who take
20- 20 plus drugs to treat many complex coexisting diseases.
For example, somebody who suffers,
uh, insomnia, suffers depression,
and has a heart disease,
all simultaneously will- will take many different drugs,
uh, altogether at once.
And the problem is that these drugs, uh,
interact with each other, um,
and they lead to new adverse side effects.
So basically, the interactions between drugs leads to additional, uh,
diseases, um, uh, or additional problems,
uh, in that human.
Uh, and of course, the number of combinations of different drugs is too big,
so we cannot experimentally or in clinical trials test
every combination of drugs to see what kind of side effects does it lead to.
So the question is, can we build up predictive engine that for
an arbitrary pair of drugs will predict how these drugs are going to interact,
and what kind of adverse side effects,
uh, they may cause?
And this is also a graph problem.
So let me tell you how we formulate it.
Um, we create this, um,
two-level heterogeneous network where triangles are the, uh, uh,
different drugs and, um,
circles are proteins in our bodies.
And then the way drugs work is that they target the different proteins.
So these are the edges between triangles and the circles.
And, um, biologists have been mapping out
the protein-protein interaction network where they
experimentally test whether two proteins physically come
together and interact to regulate a given biological process or function.
So we also know, experimentally,
which proteins interact with each other.
And this is called a protein-protein interaction network,
or also called the inter-rectum.
And then the last set of links we have in
this graph are the known side-effects where basically, for example,
the link between the node C and node M
says that if you take these two drus- drugs together,
the side-effect of type R is knowing- known to occur.
Of course, this network up here of side-effects is notoriously incomplete and,
uh, has a lot of missing connections.
So the question becomes, can we impute,
can we predict the missing edges,
missing connections, um, in this, uh,
network that would basically tell, us um,
how lay- what kind of side-effects can we expect if we take,
uh, or if a person takes two drugs simultaneously?
So the way we think of this,
we think of it as a link prediction between triangular nodes of g- um,
in the graph, where basically the question is, given, uh,
the two drugs, what kind of side effects, uh, may occur?
And what is interesting is that you can apply this method, um,
very accurately and you can discover
new side effects that haven't been known, uh, in the past.
For example, in this, uh,
in this case, um,
the mo- the model, uh,
outputted the top ten predictions it is most, uh, certain about,
where basically the way you read it is to say if you think these two drugs,
then this particular side effect is likely to occur.
And, uh, none of these side-effects are actually in the da- in the official FDA database.
So what the authors did here is they took
the top 10 predictions from the model and then they
looked in the medical literature and
clinical medical notes to see if there- are there any,
um, any reports that could,
uh, tell us whether, uh,
and provide evidence of whether this particular uh,
pair of drugs could lead to a given side-effect.
Then actually, for the five out of top 10,
we actually, um, found, uh,
that there is some research evidence that points that this,
um, that this predictions,
um, might actually be true.
So these were the machine learning tasks at the level of pairs of nodes.
So we talked about recommender systems and I talked about the side effect prediction.
Now, I wanna talk about the sub-graph level machine learning task.
Um, and here is one, um,
very recent that we are all using every day.
It's about traffic prediction.
So for example, if today you open
Google Maps and you say I wanna drive- drive from Stanford, uh,
all the way up to Berkeley, uh,
Google will tell you how long it will take you to get
there and what is your estimated time of arrival.
And I'm not sure you knew,
but actually, uh, in the end,
graph machine learning is used to make these predictions of the travel time,
and the way the graph is created is that nodes represent a road segments and,
uh, connectivity between road segments,
um, is captured by the edges of this network.
And then, um, our graph neural network approach is-
is trained that based on the conditions, uh, uh,
and traffic patterns on each of the road segment, um,
as well as the path between the source and the destination, um,
uh, of the- of the journey, uh,
the graph neural network approach is trained to predict the estimate that,
uh, time of arrival or, uh, travel time.
Um, and this- and it has been announced that actually this, um,
graph-based approach is used in production in Google Maps, so whenever, uh,
you are asking for directions,
there is actually a graph machine learning-based approach
that tells you when are you going to arrive,
uh, to a given location.
And last, I wanna talk about graph-level machine learning tasks,
uh, and some interesting impactful applications of graph-level tasks.
Um, one very recent is around drug discovery.
And actually, graph- graph-based machine learning was
used to discover new drugs, new antibiotics, right?
Antibiotics are small molecular graphs and we can represent molecules
as graphs where the nodes are atoms and edges correspond to chemical bonds.
So each molecule can be represented as a graph.
But then we ca- we have these banks,
uh, or collections of billions of molecules.
And the question is,
which molecules could have, uh, therapeutic effect.
So essentially, which molecules should be prioritized so that
biologists can pass them in the laboratory to validate or,
um, their ther- therapeutic effect.
And actually, a team at MIT was using, um, graph, uh,
based deep learning approach for
antibiotic discovery where they used a graph neural network, uh,
to classify different molecules and predict promising molecules from a pool of,
uh, billions of candidates.
And then these predictions would have further,
uh, validated, uh, in the lab.
And there is a very exciting, um,
breakthrough paper published in,
uh, journal cell, uh,
just this year about how
these graph-based approach allows us to efficiently and quickly discover,
uh, new drugs and new therapeutic uses of different,
uh, types of molecules.
Um, to further talk about drug discovery, uh,
we can think also about graph generation as a way to
discover new molecules that have never been synthesized or considered, uh, before.
And this is very useful because it allows us to generate new structures,
new molecules in various kinds of targeted ways.
For example, we can say generate new molecules that are non-toxic,
generate new molecules that have high solubility,
generate new molecules that have high drug likeness.
So we can generate now molecules as graphs in a targeted way. Not even that.
The second use case is that we can optimize
existing molecules to have a desirable property.
So basically, the use case here is that you have a small part of the molecule that has,
uh, a given therapeutic effect, for example.
And now we wanna complete, uh,
the rest of the molecule scaffold so that you improve,
um, a given property.
For example- for example, uh,
solubility and this type of deep graph, uh,
generative models, uh, can be used for tasks,
uh, like uh, molecule generation and optimization.
So, um, and the last graph-level task that I
want to talk about is a realistic, uh, physics-based simulation.
In this case, we can basically have different materials.
We represent the material as a set of particles and then
we can have a graph defined on top of,
uh, these, um, set of particles that capture which particles interact with each other.
And now the underlying task for the machine learning is to say,
predict how this graph is going to evolve in the future.
And this allows us to predict how this material is going to deform.
Um, so let me tell you how this is done.
The way this is done is that essentially we iterate,
um, the following approach.
We take the material and we represent it as a set of particles.
Based on the proximities,
interactions between the particles,
we generated the proximity graph.
Now, that we have this, uh, proximity graph,
we apply graph machine learning,
a graph neural network,
that takes the current properties, meaning positions,
as well as velocities of the particles and predict what will be the,
uh, positions and velocities of the particles in the future.
And now based on this prediction, we can move,
evolve the particles to their new positions, and then again,
we go to the first step where now based on this new proximities,
we create the new graph,
predict the new positions,
um, move the particles and keep iterating this.
And this allows for very fast and very accurate physics-based simulations.
So these were some examples of graph,
uh, of a graph-level tasks and, uh,
important applications of graph machine learning to various domains, um,
across, uh, across, uh,
sciences, industry, as well as different consumer products.